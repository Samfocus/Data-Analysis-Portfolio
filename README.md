# Data Analysis Project
<h1>This project is a capstone case study for the Google Data Analytics Professional Certificate</h1>


## Description
The following analysis is a capstone project requirement for the Google Data Analytics Certification. In this analysis, I will be focusing on Bellabeat, a wellness technology company focused on health-related products for women
<br />


## Introduction
Bellabeat, a cutting-edge manufacturer of health-focused products for women, envisions growing from a successful small company to a prominent player in the global smart device market. Bellabeat wants to analyze data that could help unlock new growth opportunities for the Company. As a junior data analyst working with the marketing team, i have been tasked with exploring and analyzing  a data from third-party health devices. The goal is to understand user habits and leverage this information to identify growth opportunities for their own products.
The project is divided into five phases: ASK, PREPARE, PROCESS, ANALYZE, SHARE, and ACT phase.
<br />

## ASK PHASE
1.	BUSINESS TASK:
     Analyze usage data from 'Bellabeat' smart devices to gain actionable insights into consumer behavior and patterns. Utilize these insights to formulate targeted and effective marketing strategies for a 
     specific 'Bellabeat' product. Present the findings and recommendations to the executive team and the marketing analytic team, aiming to enhance the product's market positioning and drive its success in       the target market.
   
   
2.	KEY DELIVERABLES
   
     - A clear summary of the business task.
  	
     - Description of all data sources used.
  	
     - Documentation of any cleaning or manipulation of data.
  	
     - A summary of analysis process.
  	
     - Supporting visualizations and key findings.
  	
     - Top high-level content recommendations based the analysis.
  	

3.	STAKEHOLDERS:
   
    The stakeholders are:
   
     - Urška Sršen: Bellabeat’s cofounder and Chief Creative Officer (primary stakeholder).
   
     - Sando Mur: Mathematician and Bellabeat’s cofounder; key member of the Bellabeat executive team (primary stakeholder).
   
     - Bellabeat marketing analytics team: A team of data analysts responsible for collecting, analyzing, and reporting data that helps guide Bellabeat’s marketing strategy (secondary stakeholder).
   

## PREPARE PHASE
In this phase I will download and import the dataset. Then make sure the data is well understood, organized and credible

1.	Data source:
   
    Stakeholder encouraged me to use public data that explores smart device users’ daily habits. She points us to a specific dataset: FitBit Fitness Tracker Data: The data source   (https://www.kaggle.com/datasets/arashnic/fitbit)


    -	This dataset was generated by respondents to a distributed survey via Amazon Mechanical Turk between 03.12.2016 and 05.12.2016.
  	
    -	The dataset is stored in 18 csv files.
  	
    -	This Kaggle data set contains personal fitness tracker from 30 fitbit users.
  	
    -	Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring. It includes information about daily activity, steps, and heart rate that can be used to explore users’ habits.


2.	Data frame description:
   
    The data frame includes the responses from 33 eligible Fitbit users to a distributed survey via Amazon Mechanical Turk between 03.12.2016 and 05.12.2016. Last modification date of the files is 2020-12-16. The files are in long and wide formats. The highest sample size of 33 distinct correspondents in dataset confers significant limitation and may not be an accurate representation of user’s population.

  - ***Summary of logged data:***

| Parameters         |                    |                    |                    |                    |  No of files  |  
| :---------:        | :----------------: | :----------------: | :----------------: | :----------------: | :-----------: |
|  Sleep             |       Daily        |                    |                    |  Minutes (Wide)    |      2        |
|  Steps             |       Daily        |      Houly         |    Minutes (Long)  |  Minutes (Wide)    |      4        |
|  Weight            |                    |                    |                    |                    |      1        |
|  Calories          |       Daily        |      Houly         |    Minutes (Long)  |  Minutes (Wide)    |      4        |
|  Intensities       |       Daily        |      Houly         |    Minutes Long)   |  Minutes (Wide)    |      4        |
|  Heart rate        |                    |                    |                    |  Seconds (Wide)    |      1        |
|  Daily Activities  |                    |                    |                    |      Wide          |      1        |
|  Mets              |                    |                    |    Minutes(Long)   |                    |      1        |
|  Mets              |                    |                    |                    |          Total     |      18       |


    

3.	Data Integrity & limitations:

   
     A good data source is expected to ROCCC which stands for Reliable, Original, Comprehensive, Current, and Cited.

    - Reliable - Mid level: The dataset contains only 33 participants and the data is licensed by CC0: Public Domain and has a Kaggle score 10.00 (100% completeness, credibility, and compatibility).

    - Original - Mid level: the dataset is provided by third party on the Public Domain data frame made available through Kaggle user Mobius.

    - Comprehensive - high level: the dataset mentrics match Bellabeat's parameters, although there is no information about their gender, geographical location, professional background or other relevant data that can impact the further data analysis

    - Current - Mid level: the data was collected 7 years ago in 2016 However, the data might still be relevant for this task. More up-to-date data should be requested if needed. This should be discussed with the stakeholders if possible.

    - Cited - low level: data collected by third party and posted on Kaggle publicly.

  4.	Tools:

    	In this case study, R will be utilized for cleaning, analyzing, and formatting the data. To process the data, I considered using Excel, SQL, and R, all relying on filters, formulas, and essential functions. However, there are some files exceeding 1 million rows, like (minuteIntensitiesNarrow_merged.csv), Excel will be inadequate, making SQL and R more suitable for further data processing.

    	but I choose to use R because:

    	- R programming loads the data more easily and faster, expecially the large files.

    	- R programming can be used more easily during every step of this analysis as it has better documentation functions.

    	- I would like to try the ggplot2 function for R visualizations, so using R in all steps will make the analysis more consistent. SQL does not have in-built visualization functionality.

## PROCESS PHASE
In R studio environment, i uploaded the packages and related libraries that will be used for analysis.
 
- Loading the R packages needed

  ```R
    library("tidyverse")
    library("skimr")
    library("janitor")
    library("dplyr")
    library("tidyr")
    library("here")
    library("lubridate")
    library("ggplot2")
   ```

- Loading the (18) dataset

  ```R
    library(readr)
  > minuteMETsNarrow_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/minuteMETsNarrow_merged.csv")
  > View(minuteMETsNarrow_merged)
  > library(readr)
  > minuteSleep_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/minuteSleep_merged.csv")
  > View(minuteSleep_merged)
  > library(readr)
  > minuteStepsNarrow_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/minuteStepsNarrow_merged.csv")
  > View(minuteStepsNarrow_merged)
  > library(readr)
  > minuteStepsWide_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/minuteStepsWide_merged.csv")
  > View(minuteStepsWide_merged)
  > library(readr)
  > sleepDay_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/sleepDay_merged.csv")
  > View(sleepDay_merged)
  > library(readr)
  > weightLogInfo_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/weightLogInfo_merged.csv")
  > View(weightLogInfo_merged)
  > library(readr)
  > hourlyCalories_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/hourlyCalories_merged.csv")
  > View(hourlyCalories_merged)
  > library(readr)
  > hourlyIntensities_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/hourlyIntensities_merged.csv")
  > View(hourlyIntensities_merged)
  > library(readr)
  > hourlySteps_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/hourlySteps_merged.csv")
  > View(hourlySteps_merged)
  > library(readr)
  > minuteCaloriesNarrow_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/minuteCaloriesNarrow_merged.csv")
  > View(minuteCaloriesNarrow_merged)
  > library(readr)
  > minuteCaloriesWide_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/minuteCaloriesWide_merged.csv")
  > View(minuteCaloriesWide_merged)
  > library(readr)
  > minuteIntensitiesNarrow_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/minuteIntensitiesNarrow_merged.csv")
  > View(minuteIntensitiesNarrow_merged)
  > library(readr)
  > minuteIntensitiesWide_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/minuteIntensitiesWide_merged.csv")
  > View(minuteIntensitiesWide_merged)
  > library(readr)
  > heartrate_seconds_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/heartrate_seconds_merged.csv")
  > View(heartrate_seconds_merged)
  > library(readr)
  > dailyActivity_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/dailyActivity_merged.csv")
  > View(dailyActivity_merged)
  > library(readr)
  > dailyCalories_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/dailyCalories_merged.csv")
  > View(dailyCalories_merged)
  > library(readr)
  > dailyIntensities_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/dailyIntensities_merged.csv")
  > View(dailyIntensities_merged)
  > library(readr)
  > dailySteps_merged <- read_csv("C:/Users/irewo/Downloads/archive (2)/Fitabase Data 4.12.16-5.12.16/fitbase Data/dailySteps_merged.csv")
  > View(dailySteps_merged)
  
   ```

- Reviewing the data:

After loading the data and reviewing it, I observed that ***dailyCalories_merged***, ***dailySteps_merged*** and ***dailyIntensities_merged*** were all included in ***dailyActivities_merged***. Therefore, I excluded the 3 data frames from the analysis. 

Furthermore, I excluded 6 more data frames:
 - minuteIntensitiesNarrow_merged and minuteIntensitiesWide_merged have a column “Intensity” with values 0,1,2,3.... These values are not clear, and there is no additional explanation for what these values mean.
 - minuteCaloriesWide_merged and minuteStepsWide_merged was also exclude because their long format is preferred
 - minuteMETsNarrow_merged was excluded because we will be using the calorie data instead.
 - minuteSleep_merged have a column “Value” with values 1,2,3 which is not clear, and there is no additional explanation on what these values mean.
   
We further went to check if the selected 9 data frames actually include the data from 30 participants, as it was mentioned in the metadata. This is important that none of the data frames have less than 30 participants to ensure their credibility for the analysis. I used the ***(n_distinct) function***.

```n_distinct(dailyActivity_merged$Id)
[1] 33
> n_distinct(sleepDay_merged$Id)
[1] 24
> n_distinct(minuteStepsNarrow_merged$Id)
[1] 33
> n_distinct(hourlySteps_merged$Id)
[1] 33
> n_distinct(weightLogInfo_merged$Id)
[1] 8
> n_distinct(minuteCaloriesNarrow_merged$Id)
[1] 33
> n_distinct(hourlyCalories_merged$Id)
[1] 33
> n_distinct(hourlyIntensities_merged$Id)
[1] 33
> n_distinct(heartrate_seconds_merged$Id)
[1] 14
```

Based on these result we excluded two (2) data frames that were extremely low, ***weightLogInfo_merged*** and ***heartrate_seconds_merged***. Furthermore, Since the task is to identify the general trends, and we already have the same data available for days and hours, I will also exclude the 2 datasets with related minutes: ***minuteCaloriesNarrow_merged*** and ***minuteStepsNarrow_merged***.

I further observed and noticed that it is also possible to aggregate the hours data frames (hourlySteps_merged,hourlyIntensities_merged & hourlyCalories_merged) to simplify their use in the further data analysis because they all have 2 common columns(Id, ActivityHour)

```
activity_hrs_list<-list(hourlySteps_merged,hourlyIntensities_merged,hourlyCalories_merged)
activity_hourly_new<-activity_hrs_list %>%
reduce(inner_join,by=c("Id","ActivityHour"))

```
Now we have only 3 data frames (sleepDay_merged$Id, dailyActivity_merged$Id, activity_hourly_new) For the analysis.


- ## Data cleaning
  
To make sure each dataset is clean, I needed to check the following:

Columns in the data should be of the same type/format.
I have noticed that in the datasets, the column Date is inconsistent: different formats of date and time.

- I converted the date column as date type.

```
   dailyActivity_merged$ActivityDate<- as.Date(dailyActivity_merged$ActivityDate,format="%m/%d/%Y")
   activity_hourly_new$ActivityHour<-as.POSIXct(activity_hourly_new$ActivityHour,format="%m/%d/%Y %I:%M:%S %p")
   sleepDay_merged$SleepDay <- as.Date(sleepDay_merged$SleepDay,format="%m/%d/%Y")
```

   - We further separated the date and time from activity_hourly_new.
     ```
     activity_hourly_new$ActivityDay<-as.Date(activity_hourly_new$ActivityHour)
     activity_hourly_new$ActivityTime<-format(as.POSIXct (activity_hourly_new$ActivityHour), format = "%H:%M:%S")
     ```
     
- All column names should be unique and consistent. Therefore I cleaned for inconsistent columns:
```
     sleepdays_clean <- clean_names(sleepDay_merged)
     activity_hours_clean <- clean_names(activity_hourly_new)
     daily_activities_clean <- clean_names(dailyActivity_merged)
```

- I checked if there are any empty fields or missing data
  ```
  sum(is.na(sleepdays_clean))
  [1] 0
  sum(is.na(activity_hours_clean))
  [1] 0
  sum(is.na(daily_activities_clean)
  [1] 0
  ```
 - I checked for duplicated rows

```
     sum(duplicated(sleepdays_clean))
     [1] 3
     sum(duplicated(activity_hours_clean))
     [1] 0
     sum(duplicated(daily_activities_clean))
     [1] 0
```

I observed that the data frame sleepdays_clean has three duplicated rows, Therefore I need to remove the duplicated rows
- Removing duplicated rows
```
sleep_days <- unique(sleepdays_clean)
```
I further rechecked if the duplicated data has been removed.
- Rechecking
  ```
  sum(duplicated(sleep_days))
  [1] 0
  ```
  
- Reviewing the final data frame (sleep_days, activity_hours_clean and daily_activities_clean)

```
     skim_without_charts(sleep_days)
     skim_without_charts(activity_hours_clean)
     skim_without_charts(daily_activities_clean)
```
- Data Preview
```
     head(sleep_days)
     head(activity_hours_clean)
     head(daily_activities_clean)
```

## ANALYZE AND SHARE PHASE
-Descriptive analysis

```
summary(daily_activities_clean)
summary(activity_hours_clean)
summary(daily_activities_clean)
 ```

- Correlation of the Total_steps and Total_Calories grouped by user id
```
-Total_calories_steps<- activity_hours_clean %>% 
  group_by(id) %>% 
  summarise(Total_calories=sum(calories), Total_steps=sum(step_total))

-summary(Total_calories_steps)

-cor(Total_calories_steps$Total_calories,Total_calories_steps$Total_steps)

 - The correlation is 0.5611333
``` 

- Ploting Total Calories against Total steps to visualize the correlation and distribution

```
ggplot(data=Total_calories_steps) +
geom_point(mapping = aes(x =Total_steps, y =Total_calories)) +
geom_smooth(method="gam", mapping = aes(x =Total_steps, y =Total_calories)) +
theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.text.x = element_text(size = 11),
    axis.text.y = element_text(size = 11),
    axis.title = element_text(size = 14)
  ) +
  labs(
    title = "Correlation between Totalsteps and Totalcalories (Month)",
    x = "Total_Steps",
    y = "Total_Calories",
  )
```
![Rplot](https://github.com/Samfocus/Portfolio-1/assets/152339100/385776cc-10c1-492d-92c1-bb912e161b29)

  
-Correlation between Hourly Total_steps and Calories

```
cor(activity_hours_clean$step_total,activity_hours_clean$calories)

 The correlation is 0.814968
```
- Ploting Hourly Calories against Hourly Total_steps to visualize the correlation and distribution
  
```
ggplot(data = activity_hours_clean) +
  geom_point(mapping = aes(x =step_total, y =calories,color=total_intensity)) +
  geom_smooth(method="gam", mapping = aes(x = step_total, y = calories)) +
  theme(
    plot.title = element_text(size = 19, face = "bold"),
    axis.text.x = element_text(size = 13),
    axis.text.y = element_text(size = 13),
    axis.title = element_text(size = 16),
    legend.title = element_text(size = 16), 
    legend.text = element_text(size = 16)
  ) +
  guides(color=guide_legend(title="Intensity")) +
  labs(
    title = "correlation between steps and calories (Hourly)",
    x = "Steps",
    y = "Calories",
  )
```
![Rplot2](https://github.com/Samfocus/Portfolio-1/assets/152339100/3cb40354-7413-46e7-8ac9-1ca703cfbef9)


##Which days of the week are users most and least active##
activity_hours_clean$weekday <- wday(activity_hours_clean$activity_day, label=TRUE)
avg_intensity_mins <- activity_hours_clean %>%
  group_by(weekday) %>%
  summarize(avg_intensity = mean(total_intensity))

ggplot(data = avg_intensity_mins, aes(x = weekday, y = avg_intensity, fill=avg_intensity)) +
  geom_bar(stat = "identity") + geom_text(aes(label=round(avg_intensity,2)), vjust=-0.5)+
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 10),
    axis.text.y = element_text(size = 9),
    plot.title = element_text(size = 17, face = "bold"),
    axis.title = element_text(size = 14),
    legend.title = element_text(size = 12), 
    legend.text = element_text(size = 10)
  ) +
  labs(
    title = "Average daily intensity time distribution per weekday",
    x = "Week days",
    y = "Average intensity minutes"
  ) +
  guides(fill=guide_legend(title="Average intensity"))


##Which hours of the day are users most and least active##

intensities_hrs_mean <- activity_hours_clean %>%
  group_by(activity_time) %>%
  summarize(
    avg_intensity_mins = mean(total_intensity)
  ) 
ggplot(data = intensities_hrs_mean, 
       aes(x = activity_time, y = avg_intensity_mins,fill=avg_intensity_mins)
) +
  geom_bar(stat = "identity") + 
  guides(fill = guide_legend(ncol = 1))+
  geom_text(aes(label=round(avg_intensity_mins,1)), vjust=-0.5,size = 3)+
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 10),
    axis.text.y = element_text(size = 10),
    plot.title = element_text(size = 18, face = "bold"),
    axis.title = element_text(size = 15),
    legend.title = element_text(size = 10), 
    legend.text = element_text(size = 10)
  ) +
  labs(
    title = " Average daily intensity time distribution per hour ",
    x = "Activity time",
    y = " Average intensity minutes"
  ) +
  guides(fill=guide_legend(title="Average intensity"))


##lightly active minutes and light active distance##
cor(daily_activities_clean$light_active_distance,daily_activities_clean$lightly_active_minutes)
##correlation=0.8856971##

ggplot(data = daily_activities_clean) +
  geom_point(mapping = aes(x = light_active_distance, y = lightly_active_minutes,color=calories)) +
  geom_smooth(mapping = aes(x = light_active_distance, y = lightly_active_minutes)) +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    axis.title = element_text(size = 15),
    legend.title = element_text(size = 15), 
    legend.text = element_text(size = 15)
  ) +
  labs(
    title = "Correlation between 'lightly active' distance\n& 'lightly active'minutes (daily)",
    x = "'Lightly active' distance",
    y = "'Lightly active' minutes"
  )


##fairly active minutes and moderately active distance##
cor(daily_activities_clean$moderately_active_distance,daily_activities_clean$fairly_active_minutes)
##correlation=0.946934)

ggplot(data = activity_days_clean) +
  geom_point(mapping = aes(x =moderately_active_distance, y = fairly_active_minutes,color=calories)) +
  geom_smooth(mapping = aes(x = moderately_active_distance, y = fairly_active_minutes)) +
  theme(
    plot.title = element_text(size = 18, face = "bold"),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    axis.title = element_text(size = 15),
    legend.title = element_text(size = 15), 
    legend.text = element_text(size = 15)
  ) +
  labs(
    title = "Relationship between 'moderately active' distance\nand 'fairly active' time (daily)",
    x = "'Moderately active' distance",
    y = "'Fairly active' minutes"
  )


##correlation between very active minutes and very active distance##
cor(daily_activities_clean$very_active_distance,daily_activities_clean$very_active_minutes)
##correlation=0.8266815##

ggplot(data = daily_activities_clean) +
  geom_point(mapping = aes(x =very_active_distance, y =very_active_minutes,color=calories)) +
  geom_smooth(mapping = aes(x = very_active_distance, y = very_active_minutes)) +
  theme(
    plot.title = element_text(size = 17, face = "bold"),
    axis.text.x = element_text(size = 11),
    axis.text.y = element_text(size = 11),
    axis.title = element_text(size = 14),
    legend.title = element_text(size = 14), 
    legend.text = element_text(size = 14)
  ) +
  labs(
    title = "Correlation between 'very active' distance\n& 'very active' minutes (daily)",
    x = "'Very active' distance",
    y = "'Very active' minutes"
  )

cor(sleep_days$total_minutes_asleep,sleep_days$total_time_in_bed)
### correlation is 0.9304224##

ggplot(data = sleep_days) +
  geom_point(mapping = aes(x = total_minutes_asleep, y =total_time_in_bed)) +
  geom_smooth(mapping = aes(x = total_minutes_asleep, y = total_time_in_bed)) +
  theme(
    plot.title = element_text(size = 17, face = "bold"),
    axis.text.x = element_text(size = 11),
    axis.text.y = element_text(size = 11),
    axis.title = element_text(size = 14),
    legend.title = element_text(size = 14), 
    legend.text = element_text(size = 14)
  ) +
  labs(
    title = "Correlation between total minutes asleep \n & total time in bed",
    x = "Total minutes asleep",
    y = "Total time in bed"
  )



sleep_days$dif_tbed_tsleep<-sleep_days$total_time_in_bed-sleep_days$total_minutes_asleep

sleep_days$weekday <- wday(sleep_days$sleep_day, label=TRUE)

ggplot(data = sleep_days) +
  geom_point(mapping = aes(x = weekday, y = dif_tbed_tsleep)) +
  geom_smooth(mapping = aes(x = weekday, y = dif_tbed_tsleep)) +
  theme(
    plot.title = element_text(size = 16, face = "bold"),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    axis.title = element_text(size = 15),
    legend.title = element_text(size = 15), 
    legend.text = element_text(size = 15)
  ) +
  labs(
    title = "Correlation between time awake in bed(minutes) and weekday",
    x = "'weekday",
    y = "'Time awake in bed"
  )











## Analyzing and Visualizing Data

As per available data, following correlations have been analyzed and visualized:

### Avg. Steps Taken Weekly

In the first analysis average steps taken by the participants weekly has been observed and found that Sunday being the lowest, 6991 steps, Tuesday and Saturday shares higher number which is above 8000 and other days are roughly around 7500 steps.

<img src='./visualizations/Average Steps Taken Through Weekdays_2color.png' width=1024>

Moreover, breakdown of each participants' average step counts throughout the weekdays have been plotted for better understanding of the movement pattern of the participants.

<img src='./visualizations/Avg Steps Taken by Participants on Weekdays.png' width=668>

#### Speculation

Participants are not consistent with maintaining their movement. On Sunday (holiday) participants tend to be more sedentary than the other days of the week. Moreover, it has been observed that most of the participants do not meet the 10,000 steps recommendation by CDC (Centers for Disease Control and Prevention) [1].

### Participants' Pattern of Being Sedentary

The below mentioned table portrays each participants'  sedentary days. This helps to observe which participant is more careful and serious about wearing the fitness tracker and measure sedentary and activity minutes.

Moreover, average sedentary minutes by participants have been plotted in color mapped table in the following picture and it can be observed that almost half of the participants seem to have higher sedentary minutes.

<img src='./visualizations/Avg Sedentary Minutes of Participants.png' width= 920>

#### Speculation

1. Half of the participants spend most of the day without any significant movement or exercise which has been marked in Red colored shades.
2. Some of the participants have high number of sedentary days, indicating fitness tracker not being worn. Similar incident might have happened for the dark red shades of the color mapped table above which might be the result of tracker not being worn for some part of the day.

### Time Spent in Different Activity Categories

Time spent in different activity types has been visualized by weekdays. This shows that most of the time spent by the participants is in the lightly active category averaging 192.7 minutes. Although average very active time (21.8 minutes) is slightly higher than the fairly active time (13.6 minutes) spent throughout the weekdays, these values are far behind the lightly active minutes.

<img src='./visualizations/Active Time.png' width=986>

#### Speculation

Light activity includes regular daily activities such as walking slowly, sitting and using computer, light standing work i.e. cooking, washing dishes etc., fishing sitting, playing instruments etc[2]. Above visualization means that most of the participants are not very active and conscious about being active and keeping healthy lifestyle.

### Calories Burnt During Active Time

Average calories burnt during active time on weekdays has been measured and visualized. Here, summation of lightly active, moderately active and very active time has been considered as "Total Active Minutes". Average of Total Active Minutes and Average of Calories Burnt throughout the weekdays have been plotted.

<img src='./visualizations/Avg Calories Burnt During Active Time.png' width=737>

Moreover, the average calories burnt by the individual participants has been analyzed and it has been observed that half of the participants have calories burnt below 2000 mark.

<img src='./visualizations/Avg Calories Burnt by Participants.png' width=737>

#### Speculation

Calorie burning requirement differs according to age, body weight, sex and calorie intake. These information are missing in this data set. Only weight information is available but for only 8 IDs and none of these weight logs represent any changes overtime. However, despite all of these missing information, as per general guideline women typically burn about 2000 calories per day and men burn about 2500 calories per day[3]. As per this guideline, the calories burnt throughout the weekdays are within this range.

### Sleeping Durations of Participants

Average sleep duration of the participants throughout the weekdays have been measured and visualized in order to get information about average sleeping hours and sleeping patterns of participants.

<img src='./visualizations/Sleep Durations.png' width=484>

#### Speculation

Although there were not age information of the participants, it is recommended that an adult (18-60 years) gets 7 hours and more sleep everyday [4]. In contrast to this information, most of the participants sleep duration is less than 7 hours on weekdays apart from Sunday, which is holiday.

## Summary

Although the data set lacked reliability and comprehensiveness due to lack of proper data collection time-line; participants age, gender, sex and profession the data set yielded some usage pattern of the Fitbit fitness tracker users. Since healthy life-style gets down to participants' calorie usage and resting pattern, the activity time, steps taken, calories burnt, sedentary habits and sleep durations have been analyzed and visualized.  Firstly, in case of activity it has been observed that most of the participants do not meet the 10,000 steps requirement by CDC. Moreover, half of the participants spend most of the day without any significant movement. However, the calorie burning requirement meets the desired value (men 2500 cal, women: 2000 cal) for half of the participants. This might be indicative of light exercise being done by the participants. On the other hand, considering sedentary condition, 1/3 of the participants have very high value of sedentary minutes. Some of the sedentary values might be indicative of tracker not being worn all the time throughout the day. On account of sleep, average sleeping duration is below 8 hour mark even Sunday being the highest  with 7.1 hours.

## Conclusion and Recommendation

As per Bellabeat stakeholder recommendation, Fitbit user open data has been analyzed to identify patterns of fitness device usage. Although the data set lacked some information, as per analysis following recommendations can be provided:

1. There has been high number of sedentary minutes observed in the data set. Potential cause of it might be not wearing the fitness tracker for long time in a day. The tracker needs to have feature to identify when it's on the users body or not. Otherwise this can produce wrong information about the user.
2. Users need to be notified about the lacking activity periodically. Users can be emailed most appropriately show as notification on the cellphone screen. In addition, calorie intake tracking can be introduced and thus curated activity plan can be suggested by the application.

## References

1. Lifestyle Coach Facilitation Guide: Post-Core: https://www.cdc.gov/diabetes/prevention/pdf/postcurriculum_session8.pdf
2. Examples of Moderate and Vigorous Physical Activity: https://www.hsph.harvard.edu/obesity-prevention-source/moderate-and-vigorous-physical-activity/
3. How Many Calories Should You Burn Daily: https://www.nike.com/a/how-many-calories-should-you-burn-daily
4. How Much Sleep Do I Need?: https://www.cdc.gov/sleep/about_sleep/how_much_sleep.html























<h2>Languages and Utilities Used</h2>

- <b>PowerShell</b> 
- <b>Diskpart</b>

<h2>Environments Used </h2>

- <b>Windows 10</b> (21H2)

<h2>Program walk-through:</h2>

<p align="center">
Launch the utility: <br/>
<img src="https://i.imgur.com/62TgaWL.png" height="80%" width="80%" alt="Disk Sanitization Steps"/>
<br />
<br />
Select the disk:  <br/>
<img src="https://i.imgur.com/tcTyMUE.png" height="80%" width="80%" alt="Disk Sanitization Steps"/>
<br />
<br />
Enter the number of passes: <br/>
<img src="https://i.imgur.com/nCIbXbg.png" height="80%" width="80%" alt="Disk Sanitization Steps"/>
<br />
<br />
Confirm your selection:  <br/>
<img src="https://i.imgur.com/cdFHBiU.png" height="80%" width="80%" alt="Disk Sanitization Steps"/>
<br />
<br />
Wait for process to complete (may take some time):  <br/>
<img src="https://i.imgur.com/JL945Ga.png" height="80%" width="80%" alt="Disk Sanitization Steps"/>
<br />
<br />
Sanitization complete:  <br/>
<img src="https://i.imgur.com/K71yaM2.png" height="80%" width="80%" alt="Disk Sanitization Steps"/>
<br />
<br />
Observe the wiped disk:  <br/>
<img src="https://i.imgur.com/AeZkvFQ.png" height="80%" width="80%" alt="Disk Sanitization Steps"/>
</p>

<!--
 ```diff
- text in red
+ text in green
! text in orange
# text in gray
@@ text in purple (and bold)@@
```
--!>
